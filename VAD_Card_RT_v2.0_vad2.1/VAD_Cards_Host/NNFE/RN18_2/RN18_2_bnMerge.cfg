[RN18_2_bnMerge]
Type = "Net"
batch = 1
Beta_1 = 0.9990
Beta_2 = 0.9990
k = 0.0000
Weight_Decay(L1) = 0.0000E+0
Weight_Decay(L2) = 0.0000E+0
LR0 = 0.0000E+0
Optimizer = "SGD"
Data_Sampling = "Random"
LR_Policy = "Manual"
Labels = ""

[input3d]
Type = "Input3D"
Channels = 3
Height = 224
Width = 224
Shifts = "0,0,0"
Scales = "1,1,1"
Data_Type = "SGL"

[conv2d]
Type = "Conv2D"
Filters = 64
Size = 7
Stride = 2
Pad_Size = 3
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "input3d"

[maxpool]
Type = "MaxPool"
Size(V) = 3
Size(H) = 3
Stride(V) = 2
Stride(H) = 2
Pad_Size(V) = 1
Pad_Size(H) = 1
Pad_Type = "Pad_Size"
Input_Layers = "conv2d"

[conv2d_3]
Type = "Conv2D"
Filters = 64
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "maxpool"

[conv2d_4]
Type = "Conv2D"
Filters = 64
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_3"

[shortcut]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_4,maxpool"

[conv2d_6]
Type = "Conv2D"
Filters = 64
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut"

[conv2d_7]
Type = "Conv2D"
Filters = 64
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_6"

[shortcut_8]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_7,shortcut"

[conv2d_9]
Type = "Conv2D"
Filters = 128
Size = 3
Stride = 2
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_8"

[conv2d_10]
Type = "Conv2D"
Filters = 128
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_9"

[conv2d_11]
Type = "Conv2D"
Filters = 128
Size = 1
Stride = 2
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Valid"
Input_Layers = "shortcut_8"

[shortcut_12]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_10,conv2d_11"

[conv2d_13]
Type = "Conv2D"
Filters = 128
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_12"

[conv2d_14]
Type = "Conv2D"
Filters = 128
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_13"

[shortcut_15]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_14,shortcut_12"

[conv2d_16]
Type = "Conv2D"
Filters = 256
Size = 3
Stride = 2
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_15"

[conv2d_17]
Type = "Conv2D"
Filters = 256
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_16"

[conv2d_18]
Type = "Conv2D"
Filters = 256
Size = 1
Stride = 2
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Valid"
Input_Layers = "shortcut_15"

[shortcut_19]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_17,conv2d_18"

[conv2d_20]
Type = "Conv2D"
Filters = 256
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_19"

[conv2d_21]
Type = "Conv2D"
Filters = 256
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_20"

[shortcut_22]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_21,shortcut_19"

[conv2d_23]
Type = "Conv2D"
Filters = 512
Size = 3
Stride = 2
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_22"

[conv2d_24]
Type = "Conv2D"
Filters = 512
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_23"

[conv2d_25]
Type = "Conv2D"
Filters = 512
Size = 1
Stride = 2
Pad_Size = 0
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Valid"
Input_Layers = "shortcut_22"

[shortcut_26]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_24,conv2d_25"

[conv2d_27]
Type = "Conv2D"
Filters = 512
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "ReLU"
Pad_Type = "Pad_Size"
Input_Layers = "shortcut_26"

[conv2d_28]
Type = "Conv2D"
Filters = 512
Size = 3
Stride = 1
Pad_Size = 1
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Pad_Type = "Pad_Size"
Input_Layers = "conv2d_27"

[shortcut_29]
Type = "SCut"
Activation = "ReLU"
Input_Layers = "conv2d_28,shortcut_26"

[avgpool]
Type = "AvgPool"
Size(V) = -1
Size(H) = -1
Stride(V) = 0
Stride(H) = 0
Pad_Size(V) = 0
Pad_Size(H) = 0
Input_Layers = "shortcut_29"

[fc]
Type = "FC"
Size = 1000
BN = FALSE
Has_Bias = TRUE
Activation = "None"
Input_Layers = "avgpool"

[Loss]
Type = "MSE"